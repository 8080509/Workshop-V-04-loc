{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_src import train_txf, families, sales, sales_shape, oil\n",
    "from data_pca import sales_pca, total_sales_pca, pca_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AUTOMOTIVE', 'BABY CARE', 'BEAUTY', 'BEVERAGES', 'BOOKS',\n",
       "       'BREAD/BAKERY', 'CELEBRATION', 'CLEANING', 'DAIRY', 'DELI', 'EGGS',\n",
       "       'FROZEN FOODS', 'GROCERY I', 'GROCERY II', 'HARDWARE',\n",
       "       'HOME AND KITCHEN I', 'HOME AND KITCHEN II', 'HOME APPLIANCES',\n",
       "       'HOME CARE', 'LADIESWEAR', 'LAWN AND GARDEN', 'LINGERIE',\n",
       "       'LIQUOR,WINE,BEER', 'MAGAZINES', 'MEATS', 'PERSONAL CARE',\n",
       "       'PET SUPPLIES', 'PLAYERS AND ELECTRONICS', 'POULTRY',\n",
       "       'PREPARED FOODS', 'PRODUCE', 'SCHOOL AND OFFICE SUPPLIES',\n",
       "       'SEAFOOD'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "families"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1688, 54, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA(n_components=100)\n",
    "# all_sales_pca = pca.fit_transform(sales.reshape(sales_shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9897929074842563)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_total.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class ARIMA in module statsmodels.tsa.arima.model:\n",
      "\n",
      "class ARIMA(statsmodels.tsa.statespace.sarimax.SARIMAX)\n",
      " |  ARIMA(endog, exog=None, order=(0, 0, 0), seasonal_order=(0, 0, 0, 0), trend=None, enforce_stationarity=True, enforce_invertibility=True, concentrate_scale=False, trend_offset=1, dates=None, freq=None, missing='none', validate_specification=True)\n",
      " |  \n",
      " |  Autoregressive Integrated Moving Average (ARIMA) model, and extensions\n",
      " |  \n",
      " |  This model is the basic interface for ARIMA-type models, including those\n",
      " |  with exogenous regressors and those with seasonal components. The most\n",
      " |  general form of the model is SARIMAX(p, d, q)x(P, D, Q, s). It also allows\n",
      " |  all specialized cases, including\n",
      " |  \n",
      " |  - autoregressive models: AR(p)\n",
      " |  - moving average models: MA(q)\n",
      " |  - mixed autoregressive moving average models: ARMA(p, q)\n",
      " |  - integration models: ARIMA(p, d, q)\n",
      " |  - seasonal models: SARIMA(P, D, Q, s)\n",
      " |  - regression with errors that follow one of the above ARIMA-type models\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  endog : array_like, optional\n",
      " |      The observed time-series process :math:`y`.\n",
      " |  exog : array_like, optional\n",
      " |      Array of exogenous regressors.\n",
      " |  order : tuple, optional\n",
      " |      The (p,d,q) order of the model for the autoregressive, differences, and\n",
      " |      moving average components. d is always an integer, while p and q may\n",
      " |      either be integers or lists of integers.\n",
      " |  seasonal_order : tuple, optional\n",
      " |      The (P,D,Q,s) order of the seasonal component of the model for the\n",
      " |      AR parameters, differences, MA parameters, and periodicity. Default\n",
      " |      is (0, 0, 0, 0). D and s are always integers, while P and Q\n",
      " |      may either be integers or lists of positive integers.\n",
      " |  trend : str{'n','c','t','ct'} or iterable, optional\n",
      " |      Parameter controlling the deterministic trend. Can be specified as a\n",
      " |      string where 'c' indicates a constant term, 't' indicates a\n",
      " |      linear trend in time, and 'ct' includes both. Can also be specified as\n",
      " |      an iterable defining a polynomial, as in `numpy.poly1d`, where\n",
      " |      `[1,1,0,1]` would denote :math:`a + bt + ct^3`. Default is 'c' for\n",
      " |      models without integration, and no trend for models with integration.\n",
      " |      Note that all trend terms are included in the model as exogenous\n",
      " |      regressors, which differs from how trends are included in ``SARIMAX``\n",
      " |      models.  See the Notes section for a precise definition of the\n",
      " |      treatment of trend terms.\n",
      " |  enforce_stationarity : bool, optional\n",
      " |      Whether or not to require the autoregressive parameters to correspond\n",
      " |      to a stationarity process.\n",
      " |  enforce_invertibility : bool, optional\n",
      " |      Whether or not to require the moving average parameters to correspond\n",
      " |      to an invertible process.\n",
      " |  concentrate_scale : bool, optional\n",
      " |      Whether or not to concentrate the scale (variance of the error term)\n",
      " |      out of the likelihood. This reduces the number of parameters by one.\n",
      " |      This is only applicable when considering estimation by numerical\n",
      " |      maximum likelihood.\n",
      " |  trend_offset : int, optional\n",
      " |      The offset at which to start time trend values. Default is 1, so that\n",
      " |      if `trend='t'` the trend is equal to 1, 2, ..., nobs. Typically is only\n",
      " |      set when the model created by extending a previous dataset.\n",
      " |  dates : array_like of datetime, optional\n",
      " |      If no index is given by `endog` or `exog`, an array-like object of\n",
      " |      datetime objects can be provided.\n",
      " |  freq : str, optional\n",
      " |      If no index is given by `endog` or `exog`, the frequency of the\n",
      " |      time-series may be specified here as a Pandas offset or offset string.\n",
      " |  missing : str\n",
      " |      Available options are 'none', 'drop', and 'raise'. If 'none', no nan\n",
      " |      checking is done. If 'drop', any observations with nans are dropped.\n",
      " |      If 'raise', an error is raised. Default is 'none'.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  This model incorporates both exogenous regressors and trend components\n",
      " |  through \"regression with ARIMA errors\". This differs from the\n",
      " |  specification estimated using ``SARIMAX`` which treats the trend\n",
      " |  components separately from any included exogenous regressors. The full\n",
      " |  specification of the model estimated here is:\n",
      " |  \n",
      " |  .. math::\n",
      " |  \n",
      " |      Y_{t}-\\delta_{0}-\\delta_{1}t-\\ldots-\\delta_{k}t^{k}-X_{t}\\beta\n",
      " |          & =\\epsilon_{t} \\\\\n",
      " |      \\left(1-L\\right)^{d}\\left(1-L^{s}\\right)^{D}\\Phi\\left(L\\right)\n",
      " |      \\Phi_{s}\\left(L\\right)\\epsilon_{t}\n",
      " |          & =\\Theta\\left(L\\right)\\Theta_{s}\\left(L\\right)\\eta_{t}\n",
      " |  \n",
      " |  where :math:`\\eta_t \\sim WN(0,\\sigma^2)` is a white noise process, L\n",
      " |  is the lag operator, and :math:`G(L)` are lag polynomials corresponding\n",
      " |  to the autoregressive (:math:`\\Phi`), seasonal autoregressive\n",
      " |  (:math:`\\Phi_s`), moving average (:math:`\\Theta`), and seasonal moving\n",
      " |  average components (:math:`\\Theta_s`).\n",
      " |  \n",
      " |  `enforce_stationarity` and `enforce_invertibility` are specified in the\n",
      " |  constructor because they affect loglikelihood computations, and so should\n",
      " |  not be changed on the fly. This is why they are not instead included as\n",
      " |  arguments to the `fit` method.\n",
      " |  \n",
      " |  See the notebook `ARMA: Sunspots Data\n",
      " |  <../examples/notebooks/generated/tsa_arma_0.html>`__ and\n",
      " |  `ARMA: Artificial Data <../examples/notebooks/generated/tsa_arma_1.html>`__\n",
      " |  for an overview.\n",
      " |  \n",
      " |  .. todo:: should concentrate_scale=True by default\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> mod = sm.tsa.arima.ARIMA(endog, order=(1, 0, 0))\n",
      " |  >>> res = mod.fit()\n",
      " |  >>> print(res.summary())\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      ARIMA\n",
      " |      statsmodels.tsa.statespace.sarimax.SARIMAX\n",
      " |      statsmodels.tsa.statespace.mlemodel.MLEModel\n",
      " |      statsmodels.tsa.base.tsa_model.TimeSeriesModel\n",
      " |      statsmodels.base.model.LikelihoodModel\n",
      " |      statsmodels.base.model.Model\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, endog, exog=None, order=(0, 0, 0), seasonal_order=(0, 0, 0, 0), trend=None, enforce_stationarity=True, enforce_invertibility=True, concentrate_scale=False, trend_offset=1, dates=None, freq=None, missing='none', validate_specification=True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, start_params=None, transformed=True, includes_fixed=False, method=None, method_kwargs=None, gls=None, gls_kwargs=None, cov_type=None, cov_kwds=None, return_params=False, low_memory=False)\n",
      " |      Fit (estimate) the parameters of the model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      start_params : array_like, optional\n",
      " |          Initial guess of the solution for the loglikelihood maximization.\n",
      " |          If None, the default is given by Model.start_params.\n",
      " |      transformed : bool, optional\n",
      " |          Whether or not `start_params` is already transformed. Default is\n",
      " |          True.\n",
      " |      includes_fixed : bool, optional\n",
      " |          If parameters were previously fixed with the `fix_params` method,\n",
      " |          this argument describes whether or not `start_params` also includes\n",
      " |          the fixed parameters, in addition to the free parameters. Default\n",
      " |          is False.\n",
      " |      method : str, optional\n",
      " |          The method used for estimating the parameters of the model. Valid\n",
      " |          options include 'statespace', 'innovations_mle', 'hannan_rissanen',\n",
      " |          'burg', 'innovations', and 'yule_walker'. Not all options are\n",
      " |          available for every specification (for example 'yule_walker' can\n",
      " |          only be used with AR(p) models).\n",
      " |      method_kwargs : dict, optional\n",
      " |          Arguments to pass to the fit function for the parameter estimator\n",
      " |          described by the `method` argument.\n",
      " |      gls : bool, optional\n",
      " |          Whether or not to use generalized least squares (GLS) to estimate\n",
      " |          regression effects. The default is False if `method='statespace'`\n",
      " |          and is True otherwise.\n",
      " |      gls_kwargs : dict, optional\n",
      " |          Arguments to pass to the GLS estimation fit method. Only applicable\n",
      " |          if GLS estimation is used (see `gls` argument for details).\n",
      " |      cov_type : str, optional\n",
      " |          The `cov_type` keyword governs the method for calculating the\n",
      " |          covariance matrix of parameter estimates. Can be one of:\n",
      " |      \n",
      " |          - 'opg' for the outer product of gradient estimator\n",
      " |          - 'oim' for the observed information matrix estimator, calculated\n",
      " |            using the method of Harvey (1989)\n",
      " |          - 'approx' for the observed information matrix estimator,\n",
      " |            calculated using a numerical approximation of the Hessian matrix.\n",
      " |          - 'robust' for an approximate (quasi-maximum likelihood) covariance\n",
      " |            matrix that may be valid even in the presence of some\n",
      " |            misspecifications. Intermediate calculations use the 'oim'\n",
      " |            method.\n",
      " |          - 'robust_approx' is the same as 'robust' except that the\n",
      " |            intermediate calculations use the 'approx' method.\n",
      " |          - 'none' for no covariance matrix calculation.\n",
      " |      \n",
      " |          Default is 'opg' unless memory conservation is used to avoid\n",
      " |          computing the loglikelihood values for each observation, in which\n",
      " |          case the default is 'oim'.\n",
      " |      cov_kwds : dict or None, optional\n",
      " |          A dictionary of arguments affecting covariance matrix computation.\n",
      " |      \n",
      " |          **opg, oim, approx, robust, robust_approx**\n",
      " |      \n",
      " |          - 'approx_complex_step' : bool, optional - If True, numerical\n",
      " |            approximations are computed using complex-step methods. If False,\n",
      " |            numerical approximations are computed using finite difference\n",
      " |            methods. Default is True.\n",
      " |          - 'approx_centered' : bool, optional - If True, numerical\n",
      " |            approximations computed using finite difference methods use a\n",
      " |            centered approximation. Default is False.\n",
      " |      return_params : bool, optional\n",
      " |          Whether or not to return only the array of maximizing parameters.\n",
      " |          Default is False.\n",
      " |      low_memory : bool, optional\n",
      " |          If set to True, techniques are applied to substantially reduce\n",
      " |          memory usage. If used, some features of the results object will\n",
      " |          not be available (including smoothed results and in-sample\n",
      " |          prediction), although out-of-sample forecasting is possible.\n",
      " |          Default is False.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ARIMAResults\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> mod = sm.tsa.arima.ARIMA(endog, order=(1, 0, 0))\n",
      " |      >>> res = mod.fit()\n",
      " |      >>> print(res.summary())\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from statsmodels.tsa.statespace.sarimax.SARIMAX:\n",
      " |  \n",
      " |  clone(self, endog, exog=None, **kwargs)\n",
      " |      Clone state space model with new data and optionally new specification\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      endog : array_like\n",
      " |          The observed time-series process :math:`y`\n",
      " |      k_states : int\n",
      " |          The dimension of the unobserved state process.\n",
      " |      exog : array_like, optional\n",
      " |          Array of exogenous regressors, shaped nobs x k. Default is no\n",
      " |          exogenous regressors.\n",
      " |      kwargs\n",
      " |          Keyword arguments to pass to the new model class to change the\n",
      " |          model specification.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      model : MLEModel subclass\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method must be implemented\n",
      " |  \n",
      " |  initialize(self)\n",
      " |      Initialize the SARIMAX model.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      These initialization steps must occur following the parent class\n",
      " |      __init__ function calls.\n",
      " |  \n",
      " |  initialize_default(self, approximate_diffuse_variance=None)\n",
      " |      Initialize default\n",
      " |  \n",
      " |  prepare_data(self)\n",
      " |      Prepare data for use in the state space representation\n",
      " |  \n",
      " |  transform_params(self, unconstrained)\n",
      " |      Transform unconstrained parameters used by the optimizer to constrained\n",
      " |      parameters used in likelihood evaluation.\n",
      " |      \n",
      " |      Used primarily to enforce stationarity of the autoregressive lag\n",
      " |      polynomial, invertibility of the moving average lag polynomial, and\n",
      " |      positive variance parameters.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      unconstrained : array_like\n",
      " |          Unconstrained parameters used by the optimizer.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      constrained : array_like\n",
      " |          Constrained parameters used in likelihood evaluation.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If the lag polynomial has non-consecutive powers (so that the\n",
      " |      coefficient is zero on some element of the polynomial), then the\n",
      " |      constraint function is not onto the entire space of invertible\n",
      " |      polynomials, although it only excludes a very small portion very close\n",
      " |      to the invertibility boundary.\n",
      " |  \n",
      " |  untransform_params(self, constrained)\n",
      " |      Transform constrained parameters used in likelihood evaluation\n",
      " |      to unconstrained parameters used by the optimizer\n",
      " |      \n",
      " |      Used primarily to reverse enforcement of stationarity of the\n",
      " |      autoregressive lag polynomial and invertibility of the moving average\n",
      " |      lag polynomial.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      constrained : array_like\n",
      " |          Constrained parameters used in likelihood evaluation.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      constrained : array_like\n",
      " |          Unconstrained parameters used by the optimizer.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If the lag polynomial has non-consecutive powers (so that the\n",
      " |      coefficient is zero on some element of the polynomial), then the\n",
      " |      constraint function is not onto the entire space of invertible\n",
      " |      polynomials, although it only excludes a very small portion very close\n",
      " |      to the invertibility boundary.\n",
      " |  \n",
      " |  update(self, params, transformed=True, includes_fixed=False, complex_step=False)\n",
      " |      Update the parameters of the model\n",
      " |      \n",
      " |      Updates the representation matrices to fill in the new parameter\n",
      " |      values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array_like\n",
      " |          Array of new parameters.\n",
      " |      transformed : bool, optional\n",
      " |          Whether or not `params` is already transformed. If set to False,\n",
      " |          `transform_params` is called. Default is True..\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : array_like\n",
      " |          Array of parameters.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from statsmodels.tsa.statespace.sarimax.SARIMAX:\n",
      " |  \n",
      " |  endog_names\n",
      " |      Names of endogenous variables\n",
      " |  \n",
      " |  initial_design\n",
      " |      Initial design matrix\n",
      " |  \n",
      " |  initial_selection\n",
      " |      Initial selection matrix\n",
      " |  \n",
      " |  initial_state_intercept\n",
      " |      Initial state intercept vector\n",
      " |  \n",
      " |  initial_transition\n",
      " |      Initial transition matrix\n",
      " |  \n",
      " |  model_latex_names\n",
      " |      The latex names of all possible model parameters.\n",
      " |  \n",
      " |  model_names\n",
      " |      The plain text names of all possible model parameters.\n",
      " |  \n",
      " |  model_orders\n",
      " |      The orders of each of the polynomials in the model.\n",
      " |  \n",
      " |  param_names\n",
      " |      List of human readable parameter names (for parameters actually\n",
      " |      included in the model).\n",
      " |  \n",
      " |  param_terms\n",
      " |      List of parameters actually included in the model, in sorted order.\n",
      " |      \n",
      " |      TODO Make this an dict with slice or indices as the values.\n",
      " |  \n",
      " |  start_params\n",
      " |      Starting parameters for maximum likelihood estimation\n",
      " |  \n",
      " |  state_names\n",
      " |      (list of str) List of human readable names for unobserved states.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from statsmodels.tsa.statespace.sarimax.SARIMAX:\n",
      " |  \n",
      " |  params_complete = ['trend', 'exog', 'ar', 'ma', 'seasonal_ar', 'season...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from statsmodels.tsa.statespace.mlemodel.MLEModel:\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |  \n",
      " |  __setitem__(self, key, value)\n",
      " |  \n",
      " |  filter(self, params, transformed=True, includes_fixed=False, complex_step=False, cov_type=None, cov_kwds=None, return_ssm=False, results_class=None, results_wrapper_class=None, low_memory=False, **kwargs)\n",
      " |      Kalman filtering\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array_like\n",
      " |          Array of parameters at which to evaluate the loglikelihood\n",
      " |          function.\n",
      " |      transformed : bool, optional\n",
      " |          Whether or not `params` is already transformed. Default is True.\n",
      " |      return_ssm : bool,optional\n",
      " |          Whether or not to return only the state space output or a full\n",
      " |          results object. Default is to return a full results object.\n",
      " |      cov_type : str, optional\n",
      " |          See `MLEResults.fit` for a description of covariance matrix types\n",
      " |          for results object.\n",
      " |      cov_kwds : dict or None, optional\n",
      " |          See `MLEResults.get_robustcov_results` for a description required\n",
      " |          keywords for alternative covariance estimators\n",
      " |      low_memory : bool, optional\n",
      " |          If set to True, techniques are applied to substantially reduce\n",
      " |          memory usage. If used, some features of the results object will\n",
      " |          not be available (including in-sample prediction), although\n",
      " |          out-of-sample forecasting is possible. Default is False.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to pass to the Kalman filter. See\n",
      " |          `KalmanFilter.filter` for more details.\n",
      " |  \n",
      " |  fit_constrained(self, constraints, start_params=None, **fit_kwds)\n",
      " |      Fit the model with some parameters subject to equality constraints.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      constraints : dict\n",
      " |          Dictionary of constraints, of the form `param_name: fixed_value`.\n",
      " |          See the `param_names` property for valid parameter names.\n",
      " |      start_params : array_like, optional\n",
      " |          Initial guess of the solution for the loglikelihood maximization.\n",
      " |          If None, the default is given by Model.start_params.\n",
      " |      **fit_kwds : keyword arguments\n",
      " |          fit_kwds are used in the optimization of the remaining parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      results : Results instance\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> mod = sm.tsa.SARIMAX(endog, order=(1, 0, 1))\n",
      " |      >>> res = mod.fit_constrained({'ar.L1': 0.5})\n",
      " |  \n",
      " |  fix_params(self, params)\n",
      " |      Fix parameters to specific values (context manager)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : dict\n",
      " |          Dictionary describing the fixed parameter values, of the form\n",
      " |          `param_name: fixed_value`. See the `param_names` property for valid\n",
      " |          parameter names.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> mod = sm.tsa.SARIMAX(endog, order=(1, 0, 1))\n",
      " |      >>> with mod.fix_params({'ar.L1': 0.5}):\n",
      " |              res = mod.fit()\n",
      " |  \n",
      " |  handle_params(self, params, transformed=True, includes_fixed=False, return_jacobian=False)\n",
      " |      Ensure model parameters satisfy shape and other requirements\n",
      " |  \n",
      " |  hessian(self, params, *args, **kwargs)\n",
      " |      Hessian matrix of the likelihood function, evaluated at the given\n",
      " |      parameters\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array_like\n",
      " |          Array of parameters at which to evaluate the hessian.\n",
      " |      *args\n",
      " |          Additional positional arguments to the `loglike` method.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to the `loglike` method.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      hessian : ndarray\n",
      " |          Hessian matrix evaluated at `params`\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This is a numerical approximation.\n",
      " |      \n",
      " |      Both args and kwargs are necessary because the optimizer from\n",
      " |      `fit` must call this function and only supports passing arguments via\n",
      " |      args (for example `scipy.optimize.fmin_l_bfgs`).\n",
      " |  \n",
      " |  impulse_responses(self, params, steps=1, impulse=0, orthogonalized=False, cumulative=False, anchor=None, exog=None, extend_model=None, extend_kwargs=None, transformed=True, includes_fixed=False, **kwargs)\n",
      " |      Impulse response function\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array_like\n",
      " |          Array of model parameters.\n",
      " |      steps : int, optional\n",
      " |          The number of steps for which impulse responses are calculated.\n",
      " |          Default is 1. Note that for time-invariant models, the initial\n",
      " |          impulse is not counted as a step, so if `steps=1`, the output will\n",
      " |          have 2 entries.\n",
      " |      impulse : int, str or array_like\n",
      " |          If an integer, the state innovation to pulse; must be between 0\n",
      " |          and `k_posdef-1`. If a str, it indicates which column of df\n",
      " |          the unit (1) impulse is given.\n",
      " |          Alternatively, a custom impulse vector may be provided; must be\n",
      " |          shaped `k_posdef x 1`.\n",
      " |      orthogonalized : bool, optional\n",
      " |          Whether or not to perform impulse using orthogonalized innovations.\n",
      " |          Note that this will also affect custum `impulse` vectors. Default\n",
      " |          is False.\n",
      " |      cumulative : bool, optional\n",
      " |          Whether or not to return cumulative impulse responses. Default is\n",
      " |          False.\n",
      " |      anchor : int, str, or datetime, optional\n",
      " |          Time point within the sample for the state innovation impulse. Type\n",
      " |          depends on the index of the given `endog` in the model. Two special\n",
      " |          cases are the strings 'start' and 'end', which refer to setting the\n",
      " |          impulse at the first and last points of the sample, respectively.\n",
      " |          Integer values can run from 0 to `nobs - 1`, or can be negative to\n",
      " |          apply negative indexing. Finally, if a date/time index was provided\n",
      " |          to the model, then this argument can be a date string to parse or a\n",
      " |          datetime type. Default is 'start'.\n",
      " |      exog : array_like, optional\n",
      " |          New observations of exogenous regressors for our-of-sample periods,\n",
      " |          if applicable.\n",
      " |      transformed : bool, optional\n",
      " |          Whether or not `params` is already transformed. Default is\n",
      " |          True.\n",
      " |      includes_fixed : bool, optional\n",
      " |          If parameters were previously fixed with the `fix_params` method,\n",
      " |          this argument describes whether or not `params` also includes\n",
      " |          the fixed parameters, in addition to the free parameters. Default\n",
      " |          is False.\n",
      " |      **kwargs\n",
      " |          If the model has time-varying design or transition matrices and the\n",
      " |          combination of `anchor` and `steps` implies creating impulse\n",
      " |          responses for the out-of-sample period, then these matrices must\n",
      " |          have updated values provided for the out-of-sample steps. For\n",
      " |          example, if `design` is a time-varying component, `nobs` is 10,\n",
      " |          `anchor=1`, and `steps` is 15, a (`k_endog` x `k_states` x 7)\n",
      " |          matrix must be provided with the new design matrix values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      impulse_responses : ndarray\n",
      " |          Responses for each endogenous variable due to the impulse\n",
      " |          given by the `impulse` argument. For a time-invariant model, the\n",
      " |          impulse responses are given for `steps + 1` elements (this gives\n",
      " |          the \"initial impulse\" followed by `steps` responses for the\n",
      " |          important cases of VAR and SARIMAX models), while for time-varying\n",
      " |          models the impulse responses are only given for `steps` elements\n",
      " |          (to avoid having to unexpectedly provide updated time-varying\n",
      " |          matrices).\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      simulate\n",
      " |          Simulate a time series according to the given state space model,\n",
      " |          optionally with specified series for the innovations.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Intercepts in the measurement and state equation are ignored when\n",
      " |      calculating impulse responses.\n",
      " |      \n",
      " |      TODO: add an option to allow changing the ordering for the\n",
      " |            orthogonalized option. Will require permuting matrices when\n",
      " |            constructing the extended model.\n",
      " |  \n",
      " |  initialize_approximate_diffuse(self, variance=None)\n",
      " |      Initialize approximate diffuse\n",
      " |  \n",
      " |  initialize_known(self, initial_state, initial_state_cov)\n",
      " |      Initialize known\n",
      " |  \n",
      " |  initialize_statespace(self, **kwargs)\n",
      " |      Initialize the state space representation\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to pass to the state space class\n",
      " |          constructor.\n",
      " |  \n",
      " |  initialize_stationary(self)\n",
      " |      Initialize stationary\n",
      " |  \n",
      " |  loglike(self, params, *args, **kwargs)\n",
      " |      Loglikelihood evaluation\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array_like\n",
      " |          Array of parameters at which to evaluate the loglikelihood\n",
      " |          function.\n",
      " |      transformed : bool, optional\n",
      " |          Whether or not `params` is already transformed. Default is True.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to pass to the Kalman filter. See\n",
      " |          `KalmanFilter.filter` for more details.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      update : modifies the internal state of the state space model to\n",
      " |               reflect new params\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      [1]_ recommend maximizing the average likelihood to avoid scale issues;\n",
      " |      this is done automatically by the base Model fit method.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] Koopman, Siem Jan, Neil Shephard, and Jurgen A. Doornik. 1999.\n",
      " |         Statistical Algorithms for Models in State Space Using SsfPack 2.2.\n",
      " |         Econometrics Journal 2 (1): 107-60. doi:10.1111/1368-423X.00023.\n",
      " |  \n",
      " |  loglikeobs(self, params, transformed=True, includes_fixed=False, complex_step=False, **kwargs)\n",
      " |      Loglikelihood evaluation\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array_like\n",
      " |          Array of parameters at which to evaluate the loglikelihood\n",
      " |          function.\n",
      " |      transformed : bool, optional\n",
      " |          Whether or not `params` is already transformed. Default is True.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to pass to the Kalman filter. See\n",
      " |          `KalmanFilter.filter` for more details.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      update : modifies the internal state of the Model to reflect new params\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      [1]_ recommend maximizing the average likelihood to avoid scale issues;\n",
      " |      this is done automatically by the base Model fit method.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] Koopman, Siem Jan, Neil Shephard, and Jurgen A. Doornik. 1999.\n",
      " |         Statistical Algorithms for Models in State Space Using SsfPack 2.2.\n",
      " |         Econometrics Journal 2 (1): 107-60. doi:10.1111/1368-423X.00023.\n",
      " |  \n",
      " |  observed_information_matrix(self, params, transformed=True, includes_fixed=False, approx_complex_step=None, approx_centered=False, **kwargs)\n",
      " |      Observed information matrix\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array_like, optional\n",
      " |          Array of parameters at which to evaluate the loglikelihood\n",
      " |          function.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to pass to the Kalman filter. See\n",
      " |          `KalmanFilter.filter` for more details.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is from Harvey (1989), which shows that the information\n",
      " |      matrix only depends on terms from the gradient. This implementation is\n",
      " |      partially analytic and partially numeric approximation, therefore,\n",
      " |      because it uses the analytic formula for the information matrix, with\n",
      " |      numerically computed elements of the gradient.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      Harvey, Andrew C. 1990.\n",
      " |      Forecasting, Structural Time Series Models and the Kalman Filter.\n",
      " |      Cambridge University Press.\n",
      " |  \n",
      " |  opg_information_matrix(self, params, transformed=True, includes_fixed=False, approx_complex_step=None, **kwargs)\n",
      " |      Outer product of gradients information matrix\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array_like, optional\n",
      " |          Array of parameters at which to evaluate the loglikelihood\n",
      " |          function.\n",
      " |      **kwargs\n",
      " |          Additional arguments to the `loglikeobs` method.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      Berndt, Ernst R., Bronwyn Hall, Robert Hall, and Jerry Hausman. 1974.\n",
      " |      Estimation and Inference in Nonlinear Structural Models.\n",
      " |      NBER Chapters. National Bureau of Economic Research, Inc.\n",
      " |  \n",
      " |  score(self, params, *args, **kwargs)\n",
      " |      Compute the score function at params.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array_like\n",
      " |          Array of parameters at which to evaluate the score.\n",
      " |      *args\n",
      " |          Additional positional arguments to the `loglike` method.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to the `loglike` method.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : ndarray\n",
      " |          Score, evaluated at `params`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This is a numerical approximation, calculated using first-order complex\n",
      " |      step differentiation on the `loglike` method.\n",
      " |      \n",
      " |      Both args and kwargs are necessary because the optimizer from\n",
      " |      `fit` must call this function and only supports passing arguments via\n",
      " |      args (for example `scipy.optimize.fmin_l_bfgs`).\n",
      " |  \n",
      " |  score_obs(self, params, method='approx', transformed=True, includes_fixed=False, approx_complex_step=None, approx_centered=False, **kwargs)\n",
      " |      Compute the score per observation, evaluated at params\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array_like\n",
      " |          Array of parameters at which to evaluate the score.\n",
      " |      **kwargs\n",
      " |          Additional arguments to the `loglike` method.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : ndarray\n",
      " |          Score per observation, evaluated at `params`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This is a numerical approximation, calculated using first-order complex\n",
      " |      step differentiation on the `loglikeobs` method.\n",
      " |  \n",
      " |  set_conserve_memory(self, conserve_memory=None, **kwargs)\n",
      " |      Set the memory conservation method\n",
      " |      \n",
      " |      By default, the Kalman filter computes a number of intermediate\n",
      " |      matrices at each iteration. The memory conservation options control\n",
      " |      which of those matrices are stored.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      conserve_memory : int, optional\n",
      " |          Bitmask value to set the memory conservation method to. See notes\n",
      " |          for details.\n",
      " |      **kwargs\n",
      " |          Keyword arguments may be used to influence the memory conservation\n",
      " |          method by setting individual boolean flags.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is rarely used. See the corresponding function in the\n",
      " |      `KalmanFilter` class for details.\n",
      " |  \n",
      " |  set_filter_method(self, filter_method=None, **kwargs)\n",
      " |      Set the filtering method\n",
      " |      \n",
      " |      The filtering method controls aspects of which Kalman filtering\n",
      " |      approach will be used.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      filter_method : int, optional\n",
      " |          Bitmask value to set the filter method to. See notes for details.\n",
      " |      **kwargs\n",
      " |          Keyword arguments may be used to influence the filter method by\n",
      " |          setting individual boolean flags. See notes for details.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is rarely used. See the corresponding function in the\n",
      " |      `KalmanFilter` class for details.\n",
      " |  \n",
      " |  set_inversion_method(self, inversion_method=None, **kwargs)\n",
      " |      Set the inversion method\n",
      " |      \n",
      " |      The Kalman filter may contain one matrix inversion: that of the\n",
      " |      forecast error covariance matrix. The inversion method controls how and\n",
      " |      if that inverse is performed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      inversion_method : int, optional\n",
      " |          Bitmask value to set the inversion method to. See notes for\n",
      " |          details.\n",
      " |      **kwargs\n",
      " |          Keyword arguments may be used to influence the inversion method by\n",
      " |          setting individual boolean flags. See notes for details.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is rarely used. See the corresponding function in the\n",
      " |      `KalmanFilter` class for details.\n",
      " |  \n",
      " |  set_smoother_output(self, smoother_output=None, **kwargs)\n",
      " |      Set the smoother output\n",
      " |      \n",
      " |      The smoother can produce several types of results. The smoother output\n",
      " |      variable controls which are calculated and returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      smoother_output : int, optional\n",
      " |          Bitmask value to set the smoother output to. See notes for details.\n",
      " |      **kwargs\n",
      " |          Keyword arguments may be used to influence the smoother output by\n",
      " |          setting individual boolean flags.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is rarely used. See the corresponding function in the\n",
      " |      `KalmanSmoother` class for details.\n",
      " |  \n",
      " |  set_stability_method(self, stability_method=None, **kwargs)\n",
      " |      Set the numerical stability method\n",
      " |      \n",
      " |      The Kalman filter is a recursive algorithm that may in some cases\n",
      " |      suffer issues with numerical stability. The stability method controls\n",
      " |      what, if any, measures are taken to promote stability.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      stability_method : int, optional\n",
      " |          Bitmask value to set the stability method to. See notes for\n",
      " |          details.\n",
      " |      **kwargs\n",
      " |          Keyword arguments may be used to influence the stability method by\n",
      " |          setting individual boolean flags. See notes for details.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is rarely used. See the corresponding function in the\n",
      " |      `KalmanFilter` class for details.\n",
      " |  \n",
      " |  simulate(self, params, nsimulations, measurement_shocks=None, state_shocks=None, initial_state=None, anchor=None, repetitions=None, exog=None, extend_model=None, extend_kwargs=None, transformed=True, includes_fixed=False, pretransformed_measurement_shocks=True, pretransformed_state_shocks=True, pretransformed_initial_state=True, random_state=None, **kwargs)\n",
      " |      Simulate a new time series following the state space model\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array_like\n",
      " |          Array of parameters to use in constructing the state space\n",
      " |          representation to use when simulating.\n",
      " |      nsimulations : int\n",
      " |          The number of observations to simulate. If the model is\n",
      " |          time-invariant this can be any number. If the model is\n",
      " |          time-varying, then this number must be less than or equal to the\n",
      " |          number of observations.\n",
      " |      measurement_shocks : array_like, optional\n",
      " |          If specified, these are the shocks to the measurement equation,\n",
      " |          :math:`\\varepsilon_t`. If unspecified, these are automatically\n",
      " |          generated using a pseudo-random number generator. If specified,\n",
      " |          must be shaped `nsimulations` x `k_endog`, where `k_endog` is the\n",
      " |          same as in the state space model.\n",
      " |      state_shocks : array_like, optional\n",
      " |          If specified, these are the shocks to the state equation,\n",
      " |          :math:`\\eta_t`. If unspecified, these are automatically\n",
      " |          generated using a pseudo-random number generator. If specified,\n",
      " |          must be shaped `nsimulations` x `k_posdef` where `k_posdef` is the\n",
      " |          same as in the state space model.\n",
      " |      initial_state : array_like, optional\n",
      " |          If specified, this is the initial state vector to use in\n",
      " |          simulation, which should be shaped (`k_states` x 1), where\n",
      " |          `k_states` is the same as in the state space model. If unspecified,\n",
      " |          but the model has been initialized, then that initialization is\n",
      " |          used. This must be specified if `anchor` is anything other than\n",
      " |          \"start\" or 0 (or else you can use the `simulate` method on a\n",
      " |          results object rather than on the model object).\n",
      " |      anchor : int, str, or datetime, optional\n",
      " |          First period for simulation. The simulation will be conditional on\n",
      " |          all existing datapoints prior to the `anchor`.  Type depends on the\n",
      " |          index of the given `endog` in the model. Two special cases are the\n",
      " |          strings 'start' and 'end'. `start` refers to beginning the\n",
      " |          simulation at the first period of the sample, and `end` refers to\n",
      " |          beginning the simulation at the first period after the sample.\n",
      " |          Integer values can run from 0 to `nobs`, or can be negative to\n",
      " |          apply negative indexing. Finally, if a date/time index was provided\n",
      " |          to the model, then this argument can be a date string to parse or a\n",
      " |          datetime type. Default is 'start'.\n",
      " |      repetitions : int, optional\n",
      " |          Number of simulated paths to generate. Default is 1 simulated path.\n",
      " |      exog : array_like, optional\n",
      " |          New observations of exogenous regressors, if applicable.\n",
      " |      transformed : bool, optional\n",
      " |          Whether or not `params` is already transformed. Default is\n",
      " |          True.\n",
      " |      includes_fixed : bool, optional\n",
      " |          If parameters were previously fixed with the `fix_params` method,\n",
      " |          this argument describes whether or not `params` also includes\n",
      " |          the fixed parameters, in addition to the free parameters. Default\n",
      " |          is False.\n",
      " |      pretransformed_measurement_shocks : bool, optional\n",
      " |          If `measurement_shocks` is provided, this flag indicates whether it\n",
      " |          should be directly used as the shocks. If False, then it is assumed\n",
      " |          to contain draws from the standard Normal distribution that must be\n",
      " |          transformed using the `obs_cov` covariance matrix. Default is True.\n",
      " |      pretransformed_state_shocks : bool, optional\n",
      " |          If `state_shocks` is provided, this flag indicates whether it\n",
      " |          should be directly used as the shocks. If False, then it is assumed\n",
      " |          to contain draws from the standard Normal distribution that must be\n",
      " |          transformed using the `state_cov` covariance matrix. Default is\n",
      " |          True.\n",
      " |      pretransformed_initial_state : bool, optional\n",
      " |          If `initial_state` is provided, this flag indicates whether it\n",
      " |          should be directly used as the initial_state. If False, then it is\n",
      " |          assumed to contain draws from the standard Normal distribution that\n",
      " |          must be transformed using the `initial_state_cov` covariance\n",
      " |          matrix. Default is True.\n",
      " |      random_state : {None, int, Generator, RandomState}, optional\n",
      " |          If `seed` is None (or `np.random`), the\n",
      " |          class:``~numpy.random.RandomState`` singleton is used.\n",
      " |          If `seed` is an int, a new class:``~numpy.random.RandomState``\n",
      " |          instance is used, seeded with `seed`.\n",
      " |          If `seed` is already a class:``~numpy.random.Generator`` or\n",
      " |          class:``~numpy.random.RandomState`` instance then that instance is\n",
      " |          used.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      simulated_obs : ndarray\n",
      " |          An array of simulated observations. If `repetitions=None`, then it\n",
      " |          will be shaped (nsimulations x k_endog) or (nsimulations,) if\n",
      " |          `k_endog=1`. Otherwise it will be shaped\n",
      " |          (nsimulations x k_endog x repetitions). If the model was given\n",
      " |          Pandas input then the output will be a Pandas object. If\n",
      " |          `k_endog > 1` and `repetitions` is not None, then the output will\n",
      " |          be a Pandas DataFrame that has a MultiIndex for the columns, with\n",
      " |          the first level containing the names of the `endog` variables and\n",
      " |          the second level containing the repetition number.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      impulse_responses\n",
      " |          Impulse response functions\n",
      " |  \n",
      " |  simulation_smoother(self, simulation_output=None, **kwargs)\n",
      " |      Retrieve a simulation smoother for the state space model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      simulation_output : int, optional\n",
      " |          Determines which simulation smoother output is calculated.\n",
      " |          Default is all (including state and disturbances).\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments, used to set the simulation output.\n",
      " |          See `set_simulation_output` for more details.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      SimulationSmoothResults\n",
      " |  \n",
      " |  smooth(self, params, transformed=True, includes_fixed=False, complex_step=False, cov_type=None, cov_kwds=None, return_ssm=False, results_class=None, results_wrapper_class=None, **kwargs)\n",
      " |      Kalman smoothing\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array_like\n",
      " |          Array of parameters at which to evaluate the loglikelihood\n",
      " |          function.\n",
      " |      transformed : bool, optional\n",
      " |          Whether or not `params` is already transformed. Default is True.\n",
      " |      return_ssm : bool,optional\n",
      " |          Whether or not to return only the state space output or a full\n",
      " |          results object. Default is to return a full results object.\n",
      " |      cov_type : str, optional\n",
      " |          See `MLEResults.fit` for a description of covariance matrix types\n",
      " |          for results object.\n",
      " |      cov_kwds : dict or None, optional\n",
      " |          See `MLEResults.get_robustcov_results` for a description required\n",
      " |          keywords for alternative covariance estimators\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to pass to the Kalman filter. See\n",
      " |          `KalmanFilter.filter` for more details.\n",
      " |  \n",
      " |  transform_jacobian(self, unconstrained, approx_centered=False)\n",
      " |      Jacobian matrix for the parameter transformation function\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      unconstrained : array_like\n",
      " |          Array of unconstrained parameters used by the optimizer.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      jacobian : ndarray\n",
      " |          Jacobian matrix of the transformation, evaluated at `unconstrained`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      transform_params\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This is a numerical approximation using finite differences. Note that\n",
      " |      in general complex step methods cannot be used because it is not\n",
      " |      guaranteed that the `transform_params` method is a real function (e.g.\n",
      " |      if Cholesky decomposition is used).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from statsmodels.tsa.statespace.mlemodel.MLEModel:\n",
      " |  \n",
      " |  from_formula(formula, data, subset=None)\n",
      " |      Not implemented for state space models\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from statsmodels.tsa.statespace.mlemodel.MLEModel:\n",
      " |  \n",
      " |  initial_variance\n",
      " |  \n",
      " |  initialization\n",
      " |  \n",
      " |  loglikelihood_burn\n",
      " |  \n",
      " |  tolerance\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from statsmodels.tsa.base.tsa_model.TimeSeriesModel:\n",
      " |  \n",
      " |  exog_names\n",
      " |      The names of the exogenous variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      " |  \n",
      " |  information(self, params)\n",
      " |      Fisher information matrix of model.\n",
      " |      \n",
      " |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : ndarray\n",
      " |          The model parameters.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from statsmodels.base.model.Model:\n",
      " |  \n",
      " |  predict(self, params, exog=None, *args, **kwargs)\n",
      " |      After a model has been fit predict returns the fitted values.\n",
      " |      \n",
      " |      This is a placeholder intended to be overwritten by individual models.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ARIMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1688, 100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_sales_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  nan, 93.14, 92.97, ..., 47.26, 47.26, 47.26], shape=(1688,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima = ARIMA(endog = total_sales_pca[:, 0], exog = oil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = arima.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               SARIMAX Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 1687\n",
      "Model:                          ARIMA   Log Likelihood              -24056.665\n",
      "Date:                Sat, 15 Feb 2025   AIC                          48119.331\n",
      "Time:                        22:53:24   BIC                          48135.623\n",
      "Sample:                             0   HQIC                         48125.365\n",
      "                               - 1687                                         \n",
      "Covariance Type:                  opg                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       2.522e+04    1.8e+06      0.014      0.989   -3.51e+06    3.56e+06\n",
      "x1          -406.5046   3.19e+04     -0.013      0.990    -6.3e+04    6.22e+04\n",
      "sigma2       3.87e+11   1.89e+10     20.524      0.000     3.5e+11    4.24e+11\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                 735.15   Jarque-Bera (JB):                41.00\n",
      "Prob(Q):                              0.00   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               1.70   Skew:                             0.31\n",
      "Prob(H) (two-sided):                  0.00   Kurtosis:                         3.46\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n"
     ]
    }
   ],
   "source": [
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_total.inverse_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.where(np.isnan(oil[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'DataFrame' has no attribute 'ffil'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mffil\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'DataFrame' has no attribute 'ffil'"
     ]
    }
   ],
   "source": [
    "# pd.DataFrame.ffil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
